# Welcome to Compass <img src="/assets/compass.png" alt="Compass Logo" height="50" /> 

Compass is a modern, open-source Large Language Model (LLM) client designed to provide a seamless AI chat experience across multiple platforms. Built with React Native and Expo, it offers a rich set of features while maintaining high performance and user experience.
The goal is to promote private, decentralized AI - whilst also maintaining access to cloud-based AI through API's for those who need or prefer it.

Try it out [here](https://nordwestt.com/compass) (only for visual demo, since browsers have CORS-restrictions)

<p align="center">
<img src="https://github.com/user-attachments/assets/f95389af-4378-466f-87e2-142638c1f422" alt="Compass Desktop" height="300" />
   &nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://github.com/user-attachments/assets/02f206c1-9522-4264-bb18-c6f3cde8e152" alt="Compass Mobile" height="300"/>
</p>


## Features

- ğŸŒ **Cross-Platform**: Buildable for iOS, Android, Linux and web
- ğŸ” **Auto-scanning for Ollama instances on network**: Just connect to the same network and Compass will find it with the press of a button.
- ğŸ¤– **Multiple LLM Providers**: Support for OpenAI, Anthropic, Ollama, and more
- ğŸ‘¥ **Character System**: Built-in characters and support for custom character creation
- ğŸ’¬ **Chat History**: Persistent conversation tracking and management
- ğŸ¤ **Inter-Character Communication**: Tag (@) characters in chats for multi-agent interactions
- ğŸ¨ **Modern UI**: Clean, responsive interface with multiple themes built in
- ğŸ” **Web search**: Paste URL's into chat to ask question about them. Automatic web search integration using SearxNg
- ğŸ—£ï¸ **Text-to-Speech (TTS)**: Natural voice output for AI responses (currently only supports ElevenLabs)
- ğŸ–¼ï¸ **Image Generation**: Generate images from text prompts (currently only supports Replicate)
- ğŸ“ **Image Gallery**: View images that have been generated
- ğŸ–¥ï¸ **Desktop Shortcut**: Alt + N to open a new chat
- ğŸ“ **Code Preview**: Preview generated html, css and javascript in a separate window

## Roadmap

- ğŸ¤ **Speech-to-Text (STT)**: Voice input capabilities
- ğŸ“ **Voice Calls**: Real-time voice conversations with AI
- ğŸ“¸ **Vision Integration**: Camera support for vision model capabilities
- ğŸ” **RAG Support**: Document analysis
- âš™ï¸ **Custom Filters**: Self-programmable filters and data processing pipes

# Installation 

## Docker
```bash
docker pull ghcr.io/nordwestt/compass:latest
```



# Development

## Get Started

It is recommended that you install Ollama and open up access, following the [guide](https://github.com/nordwestt/compass/wiki/Ollama) 

1. Install dependencies

   ```bash
   npm install
   ```

2. Start the app

   ```bash
   nvm use 18.19.0
   npx expo start
   ```

You can run the app using:

- [Development Build](https://docs.expo.dev/develop/development-builds/introduction/) - Full feature access
- [Android Emulator](https://docs.expo.dev/workflow/android-studio-emulator/) - For Android development
- [iOS Simulator](https://docs.expo.dev/workflow/ios-simulator/) - For iOS development
- [Expo Go](https://expo.dev/go) - Quick testing and development

## Building app for Linux

First install the prerequisites: https://v2.tauri.app/start/prerequisites/

Then run:

```bash
nvm use 18.19.0
npm run build:linux
```

## Contributing

I don't currently accept contributions since I'm still working on the core functionality, but I welcome feedback and suggestions for now!
